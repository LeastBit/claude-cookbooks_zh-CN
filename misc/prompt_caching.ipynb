{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 通过 Claude API 进行提示词缓存\n\n提示词缓存允许您存储和重用提示词中的上下文。这使得在提示词中包含额外信息变得更加实用——例如详细指令和示例响应——这些都有助于改善 Claude 生成的每个响应。\n\n此外，通过在提示词中充分利用提示词缓存，您可以减少超过 2 倍的延迟并节省高达 90% 的成本。当构建涉及详细书籍内容重复任务的解决方案时，这可以产生显著的节省。\n\n在本教程中，我们将演示如何在单轮和多轮对话中使用提示词缓存。"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": "## 设置\n\n首先，让我们设置必要的导入和初始化环境："
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install anthropic bs4 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "MODEL_NAME = \"claude-sonnet-4-5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "现在让我们获取一些文本内容用于示例。我们将使用简·奥斯汀的《傲慢与偏见》的文本，它大约有 187,000 个标记。"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 737525 characters from the book.\n",
      "First 500 characters:\n",
      "The Project Gutenberg eBook of Pride and Prejudice\n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBook.\n",
      "Title:\n"
     ]
    }
   ],
   "source": [
    "def fetch_article_content(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Remove script and style elements\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.decompose()\n",
    "\n",
    "    # Get text\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # Break into lines and remove leading and trailing space on each\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    # Break multi-headlines into a line each\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    # Drop blank lines\n",
    "    text = \"\\n\".join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# Fetch the content of the article\n",
    "book_url = \"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\"\n",
    "book_content = fetch_article_content(book_url)\n",
    "\n",
    "print(f\"Fetched {len(book_content)} characters from the book.\")\n",
    "print(\"First 500 characters:\")\n",
    "print(book_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 示例 1：单轮\n\n让我们演示大型文档的提示词缓存，比较缓存和非缓存 API 调用的性能和成本。"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 第 1 部分：非缓存 API 调用\n\n首先，让我们进行非缓存 API 调用。这会将提示词加载到缓存中，以便我们后续的缓存 API 调用可以从提示词缓存中受益。\n\n我们将要求一个简短的输出字符串以保持输出响应时间低，因为提示词缓存的好处仅适用于输入处理时间。"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-cached API call time: 20.37 seconds\n",
      "Non-cached API call input tokens: 17\n",
      "Non-cached API call output tokens: 8\n",
      "\n",
      "Summary (non-cached):\n",
      "[TextBlock(text='Pride and Prejudice', type='text')]\n"
     ]
    }
   ],
   "source": [
    "def make_non_cached_api_call():\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"<book>\" + book_content + \"</book>\",\n",
    "                    \"cache_control\": {\"type\": \"ephemeral\"},\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": \"What is the title of this book? Only output the title.\"},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=300,\n",
    "        messages=messages,\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    return response, end_time - start_time\n",
    "\n",
    "\n",
    "non_cached_response, non_cached_time = make_non_cached_api_call()\n",
    "\n",
    "print(f\"Non-cached API call time: {non_cached_time:.2f} seconds\")\n",
    "print(f\"Non-cached API call input tokens: {non_cached_response.usage.input_tokens}\")\n",
    "print(f\"Non-cached API call output tokens: {non_cached_response.usage.output_tokens}\")\n",
    "\n",
    "print(\"\\nSummary (non-cached):\")\n",
    "print(non_cached_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 第 2 部分：缓存 API 调用\n\n现在，让我们进行缓存 API 调用。我将在内容对象中添加 \"cache_control\": {\"type\": \"ephemeral\"} 属性，并在请求中添加 \"prompt-caching-2024-07-31\" beta 标头。这将为此次 API 调用启用提示词缓存。\n\n为了保持输出延迟恒定，我们将向 Claude 提出与之前相同的问题。请注意，此问题不是缓存内容的一部分。"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached API call time: 2.92 seconds\n",
      "Cached API call input tokens: 17\n",
      "Cached API call output tokens: 8\n",
      "\n",
      "Summary (cached):\n",
      "[TextBlock(text='Pride and Prejudice', type='text')]\n"
     ]
    }
   ],
   "source": [
    "def make_cached_api_call():\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"<book>\" + book_content + \"</book>\",\n",
    "                    \"cache_control\": {\"type\": \"ephemeral\"},\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": \"What is the title of this book? Only output the title.\"},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=300,\n",
    "        messages=messages,\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    return response, end_time - start_time\n",
    "\n",
    "\n",
    "cached_response, cached_time = make_cached_api_call()\n",
    "\n",
    "print(f\"Cached API call time: {cached_time:.2f} seconds\")\n",
    "print(f\"Cached API call input tokens: {cached_response.usage.input_tokens}\")\n",
    "print(f\"Cached API call output tokens: {cached_response.usage.output_tokens}\")\n",
    "\n",
    "print(\"\\nSummary (cached):\")\n",
    "print(cached_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "如您所见，缓存 API 调用总共只用了 3.64 秒，而非缓存 API 调用用了 21.44 秒。由于缓存，整体延迟有了显著改善。"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 示例 2：多轮对话与增量缓存\n\n现在，让我们看一个多轮对话，其中随着对话的进行，我们添加缓存断点。"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Turn 1:\n",
      "User: What is the title of this novel?\n",
      "Assistant: The title of this novel is \"Pride and Prejudice\" by Jane Austen.\n",
      "User input tokens: 4\n",
      "Output tokens: 22\n",
      "Input tokens (cache read): 0\n",
      "Input tokens (cache write): 187354\n",
      "0.0% of input prompt cached (4 tokens)\n",
      "Time taken: 20.37 seconds\n",
      "\n",
      "Turn 2:\n",
      "User: Who are Mr. and Mrs. Bennet?\n",
      "Assistant: Mr. and Mrs. Bennet are the parents of five daughters (Jane, Elizabeth, Mary, Kitty, and Lydia) in Pride and Prejudice. \n",
      "\n",
      "Mr. Bennet is an intelligent but detached father who often retreats to his library to avoid his wife's dramatics. He has a satirical wit and tends to be amused by the follies of others, including his own family members. He shows particular fondness for his second daughter Elizabeth, who shares his sharp mind and wit.\n",
      "\n",
      "Mrs. Bennet is a woman primarily focused on getting her five daughters married to wealthy men. She is described as having \"poor nerves\" and is often anxious, dramatic, and somewhat foolish. Her main goal in life is to see her daughters well-married, particularly because their family estate is entailed to a male heir (Mr. Collins), meaning her daughters will be left with little financial security after Mr. Bennet's death. She is often described as lacking sophistication and good judgment, which sometimes embarrasses her more sensible daughters, particularly Elizabeth.\n",
      "\n",
      "Their marriage is portrayed as an ill-matched one, where Mr. Bennet married Mrs. Bennet in his youth because of her beauty, only to discover they were incompatible in terms of intellect and character. This serves as a cautionary tale about marrying without proper consideration of character compatibility.\n",
      "User input tokens: 4\n",
      "Output tokens: 297\n",
      "Input tokens (cache read): 187354\n",
      "Input tokens (cache write): 36\n",
      "100.0% of input prompt cached (187358 tokens)\n",
      "Time taken: 7.53 seconds\n",
      "\n",
      "Turn 3:\n",
      "User: What is Netherfield Park?\n",
      "Assistant: Netherfield Park is a large estate near the Bennet family home of Longbourn in the novel. It becomes significant to the plot when it is rented by Mr. Bingley, a wealthy young man who moves into the neighborhood. \n",
      "\n",
      "The arrival of Mr. Bingley at Netherfield sets much of the novel's plot in motion, as he quickly develops a romantic interest in Jane Bennet, the eldest Bennet daughter. It's also through Netherfield that Elizabeth Bennet first encounters Mr. Darcy, who is staying there as Mr. Bingley's friend.\n",
      "\n",
      "Netherfield serves as an important setting for several key scenes in the novel, including:\n",
      "- The ball where Mr. Darcy first slights Elizabeth\n",
      "- Jane's illness and subsequent stay at Netherfield (where Elizabeth comes to nurse her)\n",
      "- Various social interactions between the Bennets and the Bingley-Darcy party\n",
      "\n",
      "The estate symbolizes wealth and social status in the novel, and its occupancy by Mr. Bingley represents the possibility of social and financial advancement for the Bennet family through marriage. When Bingley suddenly leaves Netherfield, it creates significant disappointment and disruption in the hopes of the Bennet family, particularly for Jane.\n",
      "User input tokens: 4\n",
      "Output tokens: 289\n",
      "Input tokens (cache read): 187390\n",
      "Input tokens (cache write): 308\n",
      "100.0% of input prompt cached (187394 tokens)\n",
      "Time taken: 6.76 seconds\n",
      "\n",
      "Turn 4:\n",
      "User: What is the main theme of this novel?\n",
      "Assistant: The main theme of \"Pride and Prejudice\" is the interplay between pride and prejudice in relationships, particularly as shown through the central romance between Elizabeth Bennet and Mr. Darcy. However, there are several important related themes:\n",
      "\n",
      "1. Pride and Prejudice:\n",
      "- Darcy's pride in his social position initially makes him appear arrogant and disdainful\n",
      "- Elizabeth's prejudice against Darcy based on first impressions and Wickham's false account\n",
      "- Both characters must overcome these flaws to find happiness together\n",
      "\n",
      "2. Marriage and Social Class:\n",
      "- The pressure on young women to marry well for financial security\n",
      "- The conflict between marrying for love versus social advantage\n",
      "- Different types of marriages are portrayed (Elizabeth/Darcy, Jane/Bingley, Lydia/Wickham, Charlotte/Collins)\n",
      "\n",
      "3. Reputation and Social Expectations:\n",
      "- The importance of reputation in Regency society\n",
      "- How behavior reflects on family honor\n",
      "- The restrictions placed on women in this period\n",
      "\n",
      "4. Personal Growth and Self-Knowledge:\n",
      "- Elizabeth and Darcy both learn to recognize their own faults\n",
      "- The importance of overcoming first impressions\n",
      "- Character development through experience and reflection\n",
      "\n",
      "5. Family and Society:\n",
      "- The role of family connections in determining social status\n",
      "- The impact of family behavior on individual prospects\n",
      "- The balance between\n",
      "User input tokens: 4\n",
      "Output tokens: 300\n",
      "Input tokens (cache read): 187698\n",
      "Input tokens (cache write): 301\n",
      "100.0% of input prompt cached (187702 tokens)\n",
      "Time taken: 7.13 seconds\n"
     ]
    }
   ],
   "source": [
    "class ConversationHistory:\n",
    "    def __init__(self):\n",
    "        # Initialize an empty list to store conversation turns\n",
    "        self.turns = []\n",
    "\n",
    "    def add_turn_assistant(self, content):\n",
    "        # Add an assistant's turn to the conversation history\n",
    "        self.turns.append({\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": content}]})\n",
    "\n",
    "    def add_turn_user(self, content):\n",
    "        # Add a user's turn to the conversation history\n",
    "        self.turns.append({\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": content}]})\n",
    "\n",
    "    def get_turns(self):\n",
    "        # Retrieve conversation turns with specific formatting\n",
    "        result = []\n",
    "        user_turns_processed = 0\n",
    "        # Iterate through turns in reverse order\n",
    "        for turn in reversed(self.turns):\n",
    "            if turn[\"role\"] == \"user\" and user_turns_processed < 1:\n",
    "                # Add the last user turn with ephemeral cache control\n",
    "                result.append(\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": turn[\"content\"][0][\"text\"],\n",
    "                                \"cache_control\": {\"type\": \"ephemeral\"},\n",
    "                            }\n",
    "                        ],\n",
    "                    }\n",
    "                )\n",
    "                user_turns_processed += 1\n",
    "            else:\n",
    "                # Add other turns as they are\n",
    "                result.append(turn)\n",
    "        # Return the turns in the original order\n",
    "        return list(reversed(result))\n",
    "\n",
    "\n",
    "# Initialize the conversation history\n",
    "conversation_history = ConversationHistory()\n",
    "\n",
    "# System message containing the book content\n",
    "# Note: 'book_content' should be defined elsewhere in the code\n",
    "system_message = f\"<file_contents> {book_content} </file_contents>\"\n",
    "\n",
    "# Predefined questions for our simulation\n",
    "questions = [\n",
    "    \"What is the title of this novel?\",\n",
    "    \"Who are Mr. and Mrs. Bennet?\",\n",
    "    \"What is Netherfield Park?\",\n",
    "    \"What is the main theme of this novel?\",\n",
    "]\n",
    "\n",
    "\n",
    "def simulate_conversation():\n",
    "    for i, question in enumerate(questions, 1):\n",
    "        print(f\"\\nTurn {i}:\")\n",
    "        print(f\"User: {question}\")\n",
    "\n",
    "        # Add user input to conversation history\n",
    "        conversation_history.add_turn_user(question)\n",
    "\n",
    "        # Record the start time for performance measurement\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Make an API call to the assistant\n",
    "        response = client.messages.create(\n",
    "            model=MODEL_NAME,\n",
    "            max_tokens=300,\n",
    "            system=[\n",
    "                {\"type\": \"text\", \"text\": system_message, \"cache_control\": {\"type\": \"ephemeral\"}},\n",
    "            ],\n",
    "            messages=conversation_history.get_turns(),\n",
    "        )\n",
    "\n",
    "        # Record the end time\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Extract the assistant's reply\n",
    "        assistant_reply = response.content[0].text\n",
    "        print(f\"Assistant: {assistant_reply}\")\n",
    "\n",
    "        # Print token usage information\n",
    "        input_tokens = response.usage.input_tokens\n",
    "        output_tokens = response.usage.output_tokens\n",
    "        input_tokens_cache_read = getattr(response.usage, \"cache_read_input_tokens\", \"---\")\n",
    "        input_tokens_cache_create = getattr(response.usage, \"cache_creation_input_tokens\", \"---\")\n",
    "        print(f\"User input tokens: {input_tokens}\")\n",
    "        print(f\"Output tokens: {output_tokens}\")\n",
    "        print(f\"Input tokens (cache read): {input_tokens_cache_read}\")\n",
    "        print(f\"Input tokens (cache write): {input_tokens_cache_create}\")\n",
    "\n",
    "        # Calculate and print the elapsed time\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        # Calculate the percentage of input prompt cached\n",
    "        total_input_tokens = input_tokens + (\n",
    "            int(input_tokens_cache_read) if input_tokens_cache_read != \"---\" else 0\n",
    "        )\n",
    "        percentage_cached = (\n",
    "            int(input_tokens_cache_read) / total_input_tokens * 100\n",
    "            if input_tokens_cache_read != \"---\" and total_input_tokens > 0\n",
    "            else 0\n",
    "        )\n",
    "\n",
    "        print(f\"{percentage_cached:.1f}% of input prompt cached ({total_input_tokens} tokens)\")\n",
    "        print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "        # Add assistant's reply to conversation history\n",
    "        conversation_history.add_turn_assistant(assistant_reply)\n",
    "\n",
    "\n",
    "# Run the simulated conversation\n",
    "simulate_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "如您在此示例中看到的，在初始缓存设置后，响应时间从近 24 秒减少到仅 7-11 秒，同时在所有答案中保持相同级别的质量。剩余延迟的大部分是由于生成响应所需的时间，这不受提示词缓存的影响。\n\n由于我们在后续轮次中不断调整缓存断点，几乎 100% 的输入标记都被缓存了，我们能够几乎瞬间读取下一条用户消息。"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}