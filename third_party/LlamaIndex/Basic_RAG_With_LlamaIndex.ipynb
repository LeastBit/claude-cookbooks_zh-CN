{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "813NspGRKhc2"
   },
   "source": "# 使用 LlamaIndex 的 RAG 流水线\n\n在这个notebook中，我们将了解如何使用LlamaIndex构建基础RAG流水线。该流水线包含以下步骤。\n\n1. 设置LLM和嵌入模型。\n2. 下载数据。\n3. 加载数据。\n4. 索引数据。\n5. 创建查询引擎。\n6. 查询。"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYHCYDecKDRZ"
   },
   "source": "### 安装"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mLTzvn__ldjd"
   },
   "outputs": [],
   "source": [
    "!pip install llama-index\n",
    "!pip install llama-index-llms-anthropic\n",
    "!pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iu-wU44BKF9c"
   },
   "source": "### 设置API密钥"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ku5rkxtIlpCs"
   },
   "outputs": [],
   "source": "os.environ[\"ANTHROPIC_API_KEY\"] = \"请输入您的Claude API密钥\""
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJTRVhkJKH4r"
   },
   "source": "### 设置LLM和嵌入模型\n\n我们将使用anthropic最新发布的 `Claude 3 Opus` 模型"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fQ0tqJL_mSe0"
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.anthropic import Anthropic\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "snc2jpj4nlXJ"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a676bbd1d04390b4449a42b98a4428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779eefefc7dc49bb9244dc54822d2195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167e22b0490c4c17a6a2ac3c1861e75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0e9e699cfb47b2bbe92756e95131ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2623fec06f4c4fcd8fbaa496a0652b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d6ff6e06214af08c3474e2c9daf830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = Anthropic(temperature=0.0, model=\"claude-opus-4-1\")\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YmN2FEQFnx6Y"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqdSyD2_KK-m"
   },
   "source": "### 下载数据"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zC7CD222n72t",
    "outputId": "42c54b8a-bec9-4c2e-9cd5-97387f7011eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-08 06:51:30--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: ‘data/paul_graham/paul_graham_essay.txt’\n",
      "\n",
      "data/paul_graham/pa 100%[===================>]  73.28K  --.-KB/s    in 0.002s  \n",
      "\n",
      "2024-03-08 06:51:30 (34.6 MB/s) - ‘data/paul_graham/paul_graham_essay.txt’ saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ea9GbN2poO3V"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dOGl_SKKUNH"
   },
   "source": "### 加载数据"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Q4hWhnhxoUBj"
   },
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"./data/paul_graham\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XM3-kLhdKRk1"
   },
   "source": "### 索引数据"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yvblCnWYKSrh"
   },
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a17Tz644KZ_P"
   },
   "source": "### 创建查询引擎"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LIT8kqYKoaRq"
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6ODGRTxKd-u"
   },
   "source": "### 测试查询"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igdrBclbKYrJ"
   },
   "outputs": [],
   "source": "response = query_engine.query(\"作者在成长过程中做了什么？\")"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ap-6RUvSozgE",
    "outputId": "37ba0327-afe7-4f1e-d862-0412085954c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided, the author worked on two main things outside of school before college: writing and programming.\n",
      "\n",
      "For writing, he wrote short stories as a beginning writer, though he felt they were awful, with hardly any plot and just characters with strong feelings.\n",
      "\n",
      "In terms of programming, in 9th grade he tried writing his first programs on an IBM 1401 computer that his school district used. He and his friend got permission to use it, programming in an early version of Fortran using punch cards. However, he had difficulty figuring out what to actually do with the computer at that stage given the limited inputs available.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}