{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 使用Claude迭代搜索Wikipedia"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[免责声明：此笔记本使用Claude 2模型创建，被认为是遗留版本。]\n\n有些问题无法让Claude信手拈来地直接回答。也许是关于时事的问题。也许您有一个非常详细的问题，而Claude没有记住答案。不用担心！通过一些提示和框架，Claude可以搜索网络来找到答案。在这个笔记本中，我们将创建一个虚拟研究助手，它能够搜索Wikipedia来找到您问题的答案。同样的方法也可以让Claude搜索更广泛的网络，或您提供的一组文档。\n\n这个方法是什么？广义上它属于\"工具使用\"的范畴。我们创建一个搜索工具，告诉Claude有关它的情况，然后让它开始工作。用伪代码表示：\n\n1. 用搜索工具的描述、最佳使用方式以及如何\"调用\"它（通过发出特殊字符串）来提示Claude。\n2. 告诉Claude您的问题。\n3. Claude像平常一样生成token。如果它产生特殊字符串，则终止token生成流，并向搜索API发出查询。\n4. 构建一个新提示，由步骤1的提示加上Claude生成到搜索调用字符串之前的所有内容，再加上API调用的结果组成。\n5. 重复直到Claude决定完成。\n\n让我们深入了解工具使用和检索的提示。"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 提示词"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be asked a question by a human user. You have access to the following tool to help answer the question. <tool_description> Search Engine Tool * The search engine will exclusively search over Wikipedia for pages similar to your query. It returns for each page its title and full page content. Use this tool if you want to get up-to-date and comprehensive information on a topic to help answer queries. Queries should be as atomic as possible -- they only need to address one part of the user's question. For example, if the user's query is \"what is the color of a basketball?\", your search query should be \"basketball\". Here's another example: if the user's question is \"Who created the first neural network?\", your first query should be \"neural network\". As you can see, these queries are quite short. Think keywords, not phrases. * At any time, you can make a call to the search engine using the following syntax: <search_query>query_word</search_query>. * You'll then get results back in <search_result> tags.</tool_description>\n"
     ]
    }
   ],
   "source": [
    "# Tool Description Prompt\n",
    "wikipedia_prompt = \"\"\"You will be asked a question by a human user. You have access to the following tool to help answer the question. <tool_description> Search Engine Tool * The search engine will exclusively search over Wikipedia for pages similar to your query. It returns for each page its title and full page content. Use this tool if you want to get up-to-date and comprehensive information on a topic to help answer queries. Queries should be as atomic as possible -- they only need to address one part of the user's question. For example, if the user's query is \"what is the color of a basketball?\", your search query should be \"basketball\". Here's another example: if the user's question is \"Who created the first neural network?\", your first query should be \"neural network\". As you can see, these queries are quite short. Think keywords, not phrases. * At any time, you can make a call to the search engine using the following syntax: <search_query>query_word</search_query>. * You'll then get results back in <search_result> tags.</tool_description>\"\"\"\n",
    "print(wikipedia_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "请注意，这个提示中有很多关于如何正确搜索Wikipedia的建议。我们都习惯于只是在Google中输入随机胡言乱语并获得不错的结果，因为查询解析逻辑很好。Wikipedia搜索不是这样的。例如：考虑查询\"在阿联酋购买土豆的最佳方式是什么\"。在Wikipedia上[这个查询的热门结果](https://en.wikipedia.org/w/index.php?search=What%27s+the+best+way+to+purchase+potatoes+in+the+United+Arab+Emirates&title=Special:Search&profile=advanced&fulltext=1&ns0=1)是关于美国的奴隶制、1973年石油危机、温迪汉堡和Tim Hortons（？？）。而Google正确地带您直接前往Carrefour UAE。"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "另一个区别是Wikipedia搜索返回整页内容。使用向量搜索，您可能会得到更窄的片段，因此您可能想要更多结果，使用更具体的查询，或两者兼而有之。重点是您的结果在这里的选择上可能会有很大差异，所以要注意！"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before beginning to research the user's question, first think for a moment inside <scratchpad> tags about what information is necessary for a well-informed answer. If the user's question is complex, you may need to decompose the query into multiple subqueries and execute them individually. Sometimes the search engine will return empty search results, or the search results may not contain the information you need. In such cases, feel free to try again with a different query. \n",
      "\n",
      "After each call to the Search Engine Tool, reflect briefly inside <search_quality></search_quality> tags about whether you now have enough information to answer, or whether more information is needed. If you have all the relevant information, write it in <information></information> tags, WITHOUT actually answering the question. Otherwise, issue a new search.\n",
      "\n",
      "Here is the user's question: <question>{query}</question> Remind yourself to make short queries in your scratchpad as you plan out your strategy.\n"
     ]
    }
   ],
   "source": [
    "retrieval_prompt = \"\"\"Before beginning to research the user's question, first think for a moment inside <scratchpad> tags about what information is necessary for a well-informed answer. If the user's question is complex, you may need to decompose the query into multiple subqueries and execute them individually. Sometimes the search engine will return empty search results, or the search results may not contain the information you need. In such cases, feel free to try again with a different query. \n",
    "\n",
    "After each call to the Search Engine Tool, reflect briefly inside <search_quality></search_quality> tags about whether you now have enough information to answer, or whether more information is needed. If you have all the relevant information, write it in <information></information> tags, WITHOUT actually answering the question. Otherwise, issue a new search.\n",
    "\n",
    "Here is the user's question: <question>{query}</question> Remind yourself to make short queries in your scratchpad as you plan out your strategy.\"\"\"\n",
    "print(retrieval_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "\n我们在这里使用scratchpad是出于正常的思维链原因——它让Claude想出一个连贯的计划来回答问题。搜索质量反思用于诱导Claude保持持久性，不要在收集所有相关信息之前就急于回答问题。但为什么要告诉Claude综合信息而不是立即回答呢？"
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a user query: <query>{query}</query>. Here is some relevant information: <information>{information}</information>. Please answer the question using the relevant information.\n"
     ]
    }
   ],
   "source": [
    "answer_prompt = \"Here is a user query: <query>{query}</query>. Here is some relevant information: <information>{information}</information>. Please answer the question using the relevant information.\"\n",
    "print(answer_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "通过提取信息并在新查询中将其呈现给Claude，我们让Claude将其所有注意力集中在将信息综合为正确答案上。没有这一步，我们发现Claude有时会预先承诺一个答案，然后用搜索结果\"证明\"它，而不是让结果指导它。"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "接下来是一大段实现搜索+检索+重新提示的伪代码的代码。"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from abc import abstractmethod\n",
    "import wikipedia\n",
    "import re\n",
    "from anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    \"\"\"\n",
    "    A single search result.\n",
    "    \"\"\"\n",
    "\n",
    "    content: str\n",
    "\n",
    "\n",
    "class SearchTool:\n",
    "    \"\"\"\n",
    "    A search tool that can run a query and return a formatted string of search results.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def raw_search(self, query: str, n_search_results_to_use: int) -> list[SearchResult]:\n",
    "        \"\"\"\n",
    "        Runs a query using the searcher, then returns the raw search results without formatting.\n",
    "\n",
    "        :param query: The query to run.\n",
    "        :param n_search_results_to_use: The number of results to return.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @abstractmethod\n",
    "    def process_raw_search_results(\n",
    "        self,\n",
    "        results: list[SearchResult],\n",
    "    ) -> list[str]:\n",
    "        \"\"\"\n",
    "        Extracts the raw search content from the search results and returns a list of strings that can be passed to Claude.\n",
    "\n",
    "        :param results: The search results to extract.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def search_results_to_string(self, extracted: list[str]) -> str:\n",
    "        \"\"\"\n",
    "        Joins and formats the extracted search results as a string.\n",
    "\n",
    "        :param extracted: The extracted search results to format.\n",
    "        \"\"\"\n",
    "        result = \"\\n\".join(\n",
    "            [\n",
    "                f'<item index=\"{i + 1}\">\\n<page_content>\\n{r}\\n</page_content>\\n</item>'\n",
    "                for i, r in enumerate(extracted)\n",
    "            ]\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    def wrap_search_results(self, extracted: list[str]) -> str:\n",
    "        \"\"\"\n",
    "        Formats the extracted search results as a string, including the <search_results> tags.\n",
    "\n",
    "        :param extracted: The extracted search results to format.\n",
    "        \"\"\"\n",
    "        return f\"\\n<search_results>\\n{self.search_results_to_string(extracted)}\\n</search_results>\"\n",
    "\n",
    "    def search(self, query: str, n_search_results_to_use: int) -> str:\n",
    "        raw_search_results = self.raw_search(query, n_search_results_to_use)\n",
    "        processed_search_results = self.process_raw_search_results(raw_search_results)\n",
    "        displayable_search_results = self.wrap_search_results(processed_search_results)\n",
    "        return displayable_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class WikipediaSearchResult(SearchResult):\n",
    "    title: str\n",
    "\n",
    "\n",
    "class WikipediaSearchTool(SearchTool):\n",
    "    def __init__(self, truncate_to_n_tokens: Optional[int] = 5000):\n",
    "        self.truncate_to_n_tokens = truncate_to_n_tokens\n",
    "        if truncate_to_n_tokens is not None:\n",
    "            self.tokenizer = Anthropic().get_tokenizer()\n",
    "\n",
    "    def raw_search(self, query: str, n_search_results_to_use: int) -> list[WikipediaSearchResult]:\n",
    "        search_results = self._search(query, n_search_results_to_use)\n",
    "        return search_results\n",
    "\n",
    "    def process_raw_search_results(self, results: list[WikipediaSearchResult]) -> list[str]:\n",
    "        processed_search_results = [\n",
    "            f\"Page Title: {result.title.strip()}\\nPage Content:\\n{self.truncate_page_content(result.content)}\"\n",
    "            for result in results\n",
    "        ]\n",
    "        return processed_search_results\n",
    "\n",
    "    def truncate_page_content(self, page_content: str) -> str:\n",
    "        if self.truncate_to_n_tokens is None:\n",
    "            return page_content.strip()\n",
    "        else:\n",
    "            return self.tokenizer.decode(\n",
    "                self.tokenizer.encode(page_content).ids[: self.truncate_to_n_tokens]\n",
    "            ).strip()\n",
    "\n",
    "    def _search(self, query: str, n_search_results_to_use: int) -> list[WikipediaSearchResult]:\n",
    "        results: list[str] = wikipedia.search(query)\n",
    "        search_results: list[WikipediaSearchResult] = []\n",
    "        for result in results:\n",
    "            if len(search_results) >= n_search_results_to_use:\n",
    "                break\n",
    "            try:\n",
    "                page = wikipedia.page(result)\n",
    "                print(page.url)\n",
    "            except Exception:\n",
    "                # The Wikipedia API is a little flaky, so we just skip over pages that fail to load\n",
    "                continue\n",
    "            content = page.content\n",
    "            title = page.title\n",
    "            search_results.append(WikipediaSearchResult(content=content, title=title))\n",
    "        return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_between_tags(tag: str, string: str, strip: bool = True) -> list[str]:\n",
    "    ext_list = re.findall(f\"<{tag}\\s?>(.+?)</{tag}\\s?>\", string, re.DOTALL)\n",
    "    if strip:\n",
    "        ext_list = [e.strip() for e in ext_list]\n",
    "    return ext_list\n",
    "\n",
    "\n",
    "class ClientWithRetrieval(Anthropic):\n",
    "    def __init__(self, search_tool: SearchTool, verbose: bool = True, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.search_tool = search_tool\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # Helper methods\n",
    "    def _search_query_stop(\n",
    "        self, partial_completion: str, n_search_results_to_use: int\n",
    "    ) -> Tuple[list[SearchResult], str]:\n",
    "        search_query = extract_between_tags(\"search_query\", partial_completion + \"</search_query>\")\n",
    "        if search_query is None:\n",
    "            raise Exception(\n",
    "                \"Completion with retrieval failed as partial completion returned mismatched <search_query> tags.\"\n",
    "            )\n",
    "        print(f\"Running search query against SearchTool: {search_query}\")\n",
    "        search_results = self.search_tool.raw_search(search_query, n_search_results_to_use)\n",
    "        extracted_search_results = self.search_tool.process_raw_search_results(search_results)\n",
    "        formatted_search_results = self.search_tool.wrap_search_results(extracted_search_results)\n",
    "        return search_results, formatted_search_results\n",
    "\n",
    "    def retrieve(\n",
    "        self,\n",
    "        query: str,\n",
    "        model: str,\n",
    "        n_search_results_to_use: int = 3,\n",
    "        stop_sequences: list[str] = [HUMAN_PROMPT],\n",
    "        max_tokens_to_sample: int = 1000,\n",
    "        max_searches_to_try: int = 5,\n",
    "        temperature: float = 1.0,\n",
    "    ) -> tuple[list[SearchResult], str]:\n",
    "        prompt = (\n",
    "            f\"{HUMAN_PROMPT} {wikipedia_prompt} {retrieval_prompt.format(query=query)}{AI_PROMPT}\"\n",
    "        )\n",
    "        starting_prompt = prompt\n",
    "        print(\"Starting prompt:\", starting_prompt)\n",
    "        token_budget = max_tokens_to_sample\n",
    "        all_raw_search_results: list[SearchResult] = []\n",
    "        for tries in range(max_searches_to_try):\n",
    "            partial_completion = self.completions.create(\n",
    "                prompt=prompt,\n",
    "                stop_sequences=stop_sequences + [\"</search_query>\"],\n",
    "                model=model,\n",
    "                max_tokens_to_sample=token_budget,\n",
    "                temperature=temperature,\n",
    "            )\n",
    "            partial_completion, stop_reason, stop_seq = (\n",
    "                partial_completion.completion,\n",
    "                partial_completion.stop_reason,\n",
    "                partial_completion.stop,\n",
    "            )\n",
    "            print(partial_completion)\n",
    "            token_budget -= self.count_tokens(partial_completion)\n",
    "            prompt += partial_completion\n",
    "            if stop_reason == \"stop_sequence\" and stop_seq == \"</search_query>\":\n",
    "                print(f\"Attempting search number {tries}.\")\n",
    "                raw_search_results, formatted_search_results = self._search_query_stop(\n",
    "                    partial_completion, n_search_results_to_use\n",
    "                )\n",
    "                prompt += \"</search_query>\" + formatted_search_results\n",
    "                all_raw_search_results += raw_search_results\n",
    "            else:\n",
    "                break\n",
    "        final_model_response = prompt[len(starting_prompt) :]\n",
    "        return all_raw_search_results, final_model_response\n",
    "\n",
    "    # Main methods\n",
    "    def completion_with_retrieval(\n",
    "        self,\n",
    "        query: str,\n",
    "        model: str,\n",
    "        n_search_results_to_use: int = 3,\n",
    "        stop_sequences: list[str] = [HUMAN_PROMPT],\n",
    "        max_tokens_to_sample: int = 1000,\n",
    "        max_searches_to_try: int = 5,\n",
    "        temperature: float = 1.0,\n",
    "    ) -> str:\n",
    "        _, retrieval_response = self.retrieve(\n",
    "            query,\n",
    "            model=model,\n",
    "            n_search_results_to_use=n_search_results_to_use,\n",
    "            stop_sequences=stop_sequences,\n",
    "            max_tokens_to_sample=max_tokens_to_sample,\n",
    "            max_searches_to_try=max_searches_to_try,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        information = extract_between_tags(\"information\", retrieval_response)[-1]\n",
    "        prompt = f\"{HUMAN_PROMPT} {answer_prompt.format(query=query, information=information)}{AI_PROMPT}\"\n",
    "        print(\"Summarizing:\\n\", prompt)\n",
    "        answer = self.completions.create(\n",
    "            prompt=prompt, model=model, temperature=temperature, max_tokens_to_sample=1000\n",
    "        ).completion\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 运行查询"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "我们准备执行查询了！让我们选择一些东西：\n- 要比较新的，这样它就不太可能在Claude的训练数据中，\n- 且是复合/复杂的问题，因此需要多次搜索。"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prompt: \n",
      "\n",
      "Human: You will be asked a question by a human user. You have access to the following tool to help answer the question. <tool_description> Search Engine Tool * The search engine will exclusively search over Wikipedia for pages similar to your query. It returns for each page its title and full page content. Use this tool if you want to get up-to-date and comprehensive information on a topic to help answer queries. Queries should be as atomic as possible -- they only need to address one part of the user's question. For example, if the user's query is \"what is the color of a basketball?\", your search query should be \"basketball\". Here's another example: if the user's question is \"Who created the first neural network?\", your first query should be \"neural network\". As you can see, these queries are quite short. Think keywords, not phrases. * At any time, you can make a call to the search engine using the following syntax: <search_query>query_word</search_query>. * You'll then get results back in <search_result> tags.</tool_description> Before beginning to research the user's question, first think for a moment inside <scratchpad> tags about what information is necessary for a well-informed answer. If the user's question is complex, you may need to decompose the query into multiple subqueries and execute them individually. Sometimes the search engine will return empty search results, or the search results may not contain the information you need. In such cases, feel free to try again with a different query. \n",
      "\n",
      "After each call to the Search Engine Tool, reflect briefly inside <search_quality></search_quality> tags about whether you now have enough information to answer, or whether more information is needed. If you have all the relevant information, write it in <information></information> tags, WITHOUT actually answering the question. Otherwise, issue a new search.\n",
      "\n",
      "Here is the user's question: <question>Which movie came out first: Oppenheimer, or Are You There God It's Me Margaret?</question> Remind yourself to make short queries in your scratchpad as you plan out your strategy.\n",
      "\n",
      "Assistant:\n",
      " <scratchpad>\n",
      "To answer this question, I need to find the release dates for the two movies:\n",
      "- Oppenheimer release date\n",
      "- Are You There God It's Me Margaret release date\n",
      "I can search for each movie title individually to get the release date.\n",
      "</scratchpad>\n",
      "\n",
      "<search_query>Oppenheimer movie\n",
      "Attempting search number 0.\n",
      "Running search query against SearchTool: ['Oppenheimer movie']\n",
      "https://en.wikipedia.org/wiki/Oppenheimer_(film)\n",
      "\n",
      "\n",
      "The search results indicate that Oppenheimer is scheduled for theatrical release on July 21, 2023. This provides the release date for Oppenheimer.\n",
      "\n",
      "<search_quality>The search results directly provided the release date for Oppenheimer, so I now have enough information to answer this part of the question.</search_quality>\n",
      "\n",
      "<search_query>Are You There God It's Me Margaret movie\n",
      "Attempting search number 1.\n",
      "Running search query against SearchTool: [\"Are You There God It's Me Margaret movie\"]\n",
      "https://en.wikipedia.org/wiki/Are_You_There_God%3F_It%27s_Me,_Margaret.\n",
      "\n",
      "\n",
      "The search results indicate that the film adaptation of Are You There God? It's Me, Margaret was released on April 28, 2023. This provides the release date for Are You There God? It's Me, Margaret. \n",
      "\n",
      "<search_quality>The search results directly stated the release date for the Are You There God? It's Me, Margaret movie adaptation, so I now have enough information to fully answer the question.</search_quality>\n",
      "\n",
      "<information>\n",
      "- Oppenheimer was released on July 21, 2023\n",
      "- Are You There God? It's Me, Margaret was released on April 28, 2023\n",
      "</information>\n",
      "\n",
      "Based on the release dates found through my searches, Oppenheimer came out first, being released on July 21, 2023, while Are You There God? It's Me, Margaret was released later on April 28, 2023.\n",
      "Summarizing:\n",
      " \n",
      "\n",
      "Human:Here is a user query: <query>Which movie came out first: Oppenheimer, or Are You There God It's Me Margaret?</query>. Here is some relevant information: <information>- Oppenheimer was released on July 21, 2023\n",
      "- Are You There God? It's Me, Margaret was released on April 28, 2023</information>. Please answer the question using the relevant information.\n",
      "\n",
      "Assistant:\n",
      " Based on the information provided, Are You There God? It's Me, Margaret was released first, on April 28, 2023. Oppenheimer was released later, on July 21, 2023.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a searcher\n",
    "wikipedia_search_tool = WikipediaSearchTool()\n",
    "ANTHROPIC_SEARCH_MODEL = \"claude-2\"\n",
    "\n",
    "client = ClientWithRetrieval(\n",
    "    api_key=os.environ[\"ANTHROPIC_API_KEY\"], verbose=True, search_tool=wikipedia_search_tool\n",
    ")\n",
    "\n",
    "query = \"Which movie came out first: Oppenheimer, or Are You There God It's Me Margaret?\"\n",
    "\n",
    "augmented_response = client.completion_with_retrieval(\n",
    "    query=query,\n",
    "    model=ANTHROPIC_SEARCH_MODEL,\n",
    "    n_search_results_to_use=1,\n",
    "    max_searches_to_try=5,\n",
    "    max_tokens_to_sample=1000,\n",
    "    temperature=0,\n",
    ")\n",
    "print(augmented_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "酷，Claude能够制定计划，执行查询，并将信息综合成准确的答案。注意：如果没有额外的信息提取步骤，Claude有时会正确确定电影的上映日期，但在最终答案中弄错顺序。让我们再试一个。"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prompt: \n",
      "\n",
      "Human: You will be asked a question by a human user. You have access to the following tool to help answer the question. <tool_description> Search Engine Tool * The search engine will exclusively search over Wikipedia for pages similar to your query. It returns for each page its title and full page content. Use this tool if you want to get up-to-date and comprehensive information on a topic to help answer queries. Queries should be as atomic as possible -- they only need to address one part of the user's question. For example, if the user's query is \"what is the color of a basketball?\", your search query should be \"basketball\". Here's another example: if the user's question is \"Who created the first neural network?\", your first query should be \"neural network\". As you can see, these queries are quite short. Think keywords, not phrases. * At any time, you can make a call to the search engine using the following syntax: <search_query>query_word</search_query>. * You'll then get results back in <search_result> tags.</tool_description> Before beginning to research the user's question, first think for a moment inside <scratchpad> tags about what information is necessary for a well-informed answer. If the user's question is complex, you may need to decompose the query into multiple subqueries and execute them individually. Sometimes the search engine will return empty search results, or the search results may not contain the information you need. In such cases, feel free to try again with a different query. \n",
      "\n",
      "After each call to the Search Engine Tool, reflect briefly inside <search_quality></search_quality> tags about whether you now have enough information to answer, or whether more information is needed. If you have all the relevant information, write it in <information></information> tags, WITHOUT actually answering the question. Otherwise, issue a new search.\n",
      "\n",
      "Here is the user's question: <question>Who won the 2023 NBA championship? Who was that team's best player in the year 2009?</question> Remind yourself to make short queries in your scratchpad as you plan out your strategy.\n",
      "\n",
      "Assistant:\n",
      " <scratchpad>\n",
      "To answer this question, I need to find:\n",
      "1. The team that won the 2023 NBA championship\n",
      "2. The best player on that team in 2009\n",
      "I can search for these things separately.\n",
      "</scratchpad>\n",
      "\n",
      "<search_query>2023 nba championship winner\n",
      "Attempting search number 0.\n",
      "Running search query against SearchTool: ['2023 nba championship winner']\n",
      "https://en.wikipedia.org/wiki/List_of_NBA_champions\n",
      "\n",
      "\n",
      "<search_quality>The search results contain the team that won the 2023 NBA championship, so I have the information I need to answer the first part of the question.</search_quality>\n",
      "\n",
      "<information>\n",
      "The Denver Nuggets won the 2023 NBA championship.\n",
      "</information>\n",
      "\n",
      "<search_query>denver nuggets best player 2009\n",
      "Attempting search number 1.\n",
      "Running search query against SearchTool: ['denver nuggets best player 2009']\n",
      "https://en.wikipedia.org/wiki/2009%E2%80%9310_Denver_Nuggets_season\n",
      "\n",
      "\n",
      "<search_quality>The search results indicate that Carmelo Anthony was the Nuggets' best player in 2009, so I now have all the information needed to fully answer the question.</search_quality>\n",
      "\n",
      "<information>\n",
      "- The Denver Nuggets won the 2023 NBA championship.\n",
      "- Carmelo Anthony was the Nuggets' best player in 2009.\n",
      "</information>\n",
      "Summarizing:\n",
      " \n",
      "\n",
      "Human:Here is a user query: <query>Who won the 2023 NBA championship? Who was that team's best player in the year 2009?</query>. Here is some relevant information: <information>- The Denver Nuggets won the 2023 NBA championship.\n",
      "- Carmelo Anthony was the Nuggets' best player in 2009.</information>. Please answer the question using the relevant information.\n",
      "\n",
      "Assistant:\n",
      " <response>\n",
      "Based on the provided information:\n",
      "- The Denver Nuggets won the 2023 NBA championship. \n",
      "- Carmelo Anthony was the Nuggets' best player in 2009.\n",
      "</response>\n"
     ]
    }
   ],
   "source": [
    "augmented_response = client.completion_with_retrieval(\n",
    "    query=\"Who won the 2023 NBA championship? Who was that team's best player in the year 2009?\",\n",
    "    model=ANTHROPIC_SEARCH_MODEL,\n",
    "    n_search_results_to_use=1,\n",
    "    max_searches_to_try=5,\n",
    "    max_tokens_to_sample=1000,\n",
    "    temperature=0,\n",
    ")\n",
    "print(augmented_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "就是这样！您可能注意到搜索工具代码很好且抽象，可以进行微小修改以适应您选择的搜索API。只需记住向Claude解释它需要使用工具的任何提示。您甚至可以给Claude一些理想查询计划和查询结构的少样本示例，以进一步改善性能。"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}