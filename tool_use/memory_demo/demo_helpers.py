"""
è®°å¿†æ¼”ç¤ºæ‰‹å†Œçš„å¸®åŠ©å‡½æ•°ã€‚

æ­¤æ¨¡å—æä¾›å¯é‡ç”¨çš„å‡½æ•°ï¼Œç”¨äºè¿è¡Œä¸ Claude çš„å¯¹è¯å¾ªç¯ã€
å¤„ç†å·¥å…·æ‰§è¡Œå’Œç®¡ç†ä¸Šä¸‹æ–‡ã€‚
"""

from typing import Any

from anthropic import Anthropic
from memory_tool import MemoryToolHandler


def execute_tool(tool_use: Any, memory_handler: MemoryToolHandler) -> str:
    """
    æ‰§è¡Œå·¥å…·ä½¿ç”¨å¹¶è¿”å›ç»“æœã€‚

    Args:
        tool_use: æ¥è‡ª Claude å“åº”çš„å·¥å…·ä½¿ç”¨å¯¹è±¡
        memory_handler: è®°å¿†å·¥å…·å¤„ç†å™¨å®ä¾‹

    Returns:
        str: å·¥å…·æ‰§è¡Œçš„ç»“æœ
    """
    if tool_use.name == "memory":
        result = memory_handler.execute(**tool_use.input)
        return result.get("success") or result.get("error", "æœªçŸ¥é”™è¯¯")
    return f"æœªçŸ¥å·¥å…·: {tool_use.name}"


def run_conversation_turn(
    client: Anthropic,
    model: str,
    messages: list[dict[str, Any]],
    memory_handler: MemoryToolHandler,
    system: str,
    context_management: dict[str, Any] | None = None,
    max_tokens: int = 1024,
    verbose: bool = False,
) -> tuple[Any, list[dict[str, Any]], list[dict[str, Any]]]:
    """
    è¿è¡Œå•æ¬¡å¯¹è¯è½®æ¬¡ï¼Œå¤„ç†å·¥å…·ä½¿ç”¨ã€‚

    Args:
        client: Anthropic å®¢æˆ·ç«¯å®ä¾‹
        model: è¦ä½¿ç”¨çš„æ¨¡å‹
        messages: å½“å‰å¯¹è¯æ¶ˆæ¯
        memory_handler: è®°å¿†å·¥å…·å¤„ç†å™¨å®ä¾‹
        system: ç³»ç»Ÿæç¤º
        context_management: å¯é€‰çš„ä¸Šä¸‹æ–‡ç®¡ç†é…ç½®
        max_tokens: å“åº”çš„æœ€å¤§ä»¤ç‰Œæ•°
        verbose: æ˜¯å¦æ‰“å°å·¥å…·æ“ä½œ

    Returns:
        (å“åº”, åŠ©æ‰‹å†…å®¹, å·¥å…·ç»“æœ) çš„å…ƒç»„
    """
    memory_tool: dict[str, Any] = {"type": "memory_20250818", "name": "memory"}

    request_params: dict[str, Any] = {
        "model": model,
        "max_tokens": max_tokens,
        "system": system,
        "messages": messages,
        "tools": [memory_tool],
        "betas": ["context-management-2025-06-27"],
    }

    if context_management:
        request_params["context_management"] = context_management

    response = client.beta.messages.create(**request_params)

    assistant_content = []
    tool_results = []

    for content in response.content:
        if content.type == "text":
            if verbose:
                print(f"ğŸ’¬ Claude: {content.text}\n")
            assistant_content.append({"type": "text", "text": content.text})
        elif content.type == "tool_use":
            if verbose:
                cmd = content.input.get("command")
                path = content.input.get("path", "")
                print(f"  ğŸ”§ è®°å¿†å·¥å…·: {cmd} {path}")

            result = execute_tool(content, memory_handler)

            if verbose:
                result_preview = result[:80] + "..." if len(result) > 80 else result
                print(f"  âœ“ ç»“æœ: {result_preview}")

            assistant_content.append(
                {"type": "tool_use", "id": content.id, "name": content.name, "input": content.input}
            )
            tool_results.append(
                {"type": "tool_result", "tool_use_id": content.id, "content": result}
            )

    return response, assistant_content, tool_results


def run_conversation_loop(
    client: Anthropic,
    model: str,
    messages: list[dict[str, Any]],
    memory_handler: MemoryToolHandler,
    system: str,
    context_management: dict[str, Any] | None = None,
    max_tokens: int = 1024,
    max_turns: int = 5,
    verbose: bool = False,
) -> Any:
    """
    è¿è¡Œå®Œæ•´çš„å¯¹è¯å¾ªç¯ï¼Œç›´åˆ° Claude åœæ­¢ä½¿ç”¨å·¥å…·ã€‚

    Args:
        client: Anthropic å®¢æˆ·ç«¯å®ä¾‹
        model: è¦ä½¿ç”¨çš„æ¨¡å‹
        messages: å½“å‰å¯¹è¯æ¶ˆæ¯ï¼ˆå°†è¿›è¡Œå°±åœ°ä¿®æ”¹ï¼‰
        memory_handler: è®°å¿†å·¥å…·å¤„ç†å™¨å®ä¾‹
        system: ç³»ç»Ÿæç¤º
        context_management: å¯é€‰çš„ä¸Šä¸‹æ–‡ç®¡ç†é…ç½®
        max_tokens: å“åº”çš„æœ€å¤§ä»¤ç‰Œæ•°
        max_turns: æœ€å¤§è½®æ¬¡æ•°ï¼Œä»¥é˜²æ­¢æ— é™å¾ªç¯
        verbose: æ˜¯å¦æ‰“å°è¿›åº¦

    Returns:
        æœ€ç»ˆçš„ API å“åº”
    """
    turn = 1
    response = None

    while turn <= max_turns:
        if verbose:
            print(f"\nğŸ”„ è½®æ¬¡ {turn}:")

        response, assistant_content, tool_results = run_conversation_turn(
            client=client,
            model=model,
            messages=messages,
            memory_handler=memory_handler,
            system=system,
            context_management=context_management,
            max_tokens=max_tokens,
            verbose=verbose,
        )

        messages.append({"role": "assistant", "content": assistant_content})

        if tool_results:
            messages.append({"role": "user", "content": tool_results})
            turn += 1
        else:
            # æ²¡æœ‰æ›´å¤šå·¥å…·ä½¿ç”¨ï¼Œå¯¹è¯å®Œæˆ
            break

    return response


def print_context_management_info(response: Any) -> tuple[bool, int]:
    """
    æ‰“å°å“åº”ä¸­çš„ä¸Šä¸‹æ–‡ç®¡ç†ä¿¡æ¯ã€‚

    Args:
        response: è¦åˆ†æçš„ API å“åº”

    Returns:
        (ä¸Šä¸‹æ–‡æ˜¯å¦æ¸…é™¤, ä¿å­˜çš„ä»¤ç‰Œæ•°) çš„å…ƒç»„
    """
    context_cleared = False
    saved_tokens = 0

    if hasattr(response, "context_management") and response.context_management:
        edits = getattr(response.context_management, "applied_edits", [])
        if edits:
            context_cleared = True
            cleared_uses = getattr(edits[0], "cleared_tool_uses", 0)
            saved_tokens = getattr(edits[0], "cleared_input_tokens", 0)
            print("  âœ‚ï¸  è§¦å‘äº†ä¸Šä¸‹æ–‡ç¼–è¾‘!")
            print(f"      â€¢ æ¸…é™¤äº† {cleared_uses} æ¬¡å·¥å…·ä½¿ç”¨")
            print(f"      â€¢ èŠ‚çœäº† {saved_tokens:,} ä¸ªä»¤ç‰Œ")
            print(f"      â€¢ æ¸…é™¤å: {response.usage.input_tokens:,} ä¸ªä»¤ç‰Œ")
        else:
            # æ£€æŸ¥æˆ‘ä»¬æ˜¯å¦èƒ½çœ‹åˆ°å®ƒæœªè§¦å‘çš„åŸå› 
            skipped_edits = getattr(response.context_management, "skipped_edits", [])
            if skipped_edits:
                print("  â„¹ï¸  è·³è¿‡äº†ä¸Šä¸‹æ–‡æ¸…é™¤:")
                for skip in skipped_edits:
                    reason = getattr(skip, "reason", "unknown")
                    print(f"      â€¢ åŸå› : {reason}")
            else:
                print("  â„¹ï¸  ä¸Šä¸‹æ–‡ä½äºé˜ˆå€¼ - æœªè§¦å‘æ¸…é™¤")
    else:
        print("  â„¹ï¸  æœªåº”ç”¨ä¸Šä¸‹æ–‡ç®¡ç†")

    return context_cleared, saved_tokens
